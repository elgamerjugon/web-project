{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\alex_\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\alex_\\anaconda3\\lib\\site-packages (from bs4) (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\alex_\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (1.8)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install bs4\n",
    "import requests\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import feedparser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Índice</th>\n",
       "      <th>Último</th>\n",
       "      <th>Hora</th>\n",
       "      <th>Anterior</th>\n",
       "      <th>Variación</th>\n",
       "      <th>Variación Ptos.</th>\n",
       "      <th>Máximo</th>\n",
       "      <th>Hora</th>\n",
       "      <th>Mínimo</th>\n",
       "      <th>Hora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S&amp;P/BMV FIBRAS</td>\n",
       "      <td>223.08</td>\n",
       "      <td>15:16</td>\n",
       "      <td>223.73</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>226.94</td>\n",
       "      <td>9:02</td>\n",
       "      <td>221.48</td>\n",
       "      <td>2:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S&amp;P/BMV IRT MidCap</td>\n",
       "      <td>347.71</td>\n",
       "      <td>15:16</td>\n",
       "      <td>348.29</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>351.24</td>\n",
       "      <td>9:02</td>\n",
       "      <td>346.83</td>\n",
       "      <td>9:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Índice  Último   Hora Anterior  Variación Variación Ptos.  \\\n",
       "4      S&P/BMV FIBRAS  223.08  15:16   223.73      -0.29           -0.65   \n",
       "7  S&P/BMV IRT MidCap  347.71  15:16   348.29      -0.17           -0.58   \n",
       "\n",
       "   Máximo  Hora  Mínimo  Hora  \n",
       "4  226.94  9:02  221.48  2:15  \n",
       "7  351.24  9:02  346.83  9:46  "
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrapping(soup):\n",
    "    #Obtengo los principales índices para el cierre anterior (es una tabla)\n",
    "    tabla_indices = soup.select(\"table table table table table th\")\n",
    "    # tabla_indices\n",
    "    headers = [element.text for element in tabla_indices[0:10]]\n",
    "\n",
    "    # Guardo los nombres de la columna para la tabla\n",
    "    headers\n",
    "\n",
    "    #Obtengo todos los datos que se encuentran en la tabla, en los tabledata\n",
    "    datos  = soup.select(\"table table table table table td\")\n",
    "\n",
    "    #Tomo el texto de cada elemento y los guardo, sin sus etiquetas\n",
    "    datos = [element.text for element in datos]\n",
    "\n",
    "    #Creo una lista de listas donde guardaré los valores para cada fila que luego pasaré al Data Frame\n",
    "    filas = [[]]\n",
    "\n",
    "    #Hago un slicing por cada 10 elementos que son los valores para cada columna por fila\n",
    "    for num in range(0,71, 10):\n",
    "        filas.append(datos[num:num+10])\n",
    "\n",
    "    df = pd.DataFrame(filas, columns = headers)\n",
    "    return df\n",
    "#     print(df)\n",
    "\n",
    "#Obtengo el RSS de los cierres diarios de la BMV\n",
    "def scrapping_RSS():\n",
    "    url = \"http://feeds.feedburner.com/BmvBoletin\"\n",
    "\n",
    "    rss = feedparser.parse(url)\n",
    "\n",
    "    #Guardo cada una de las entradas existentes en el RSS\n",
    "    rss_df = pd.DataFrame(rss.entries)\n",
    "\n",
    "    #Ordeno las entradas para tener en el primer elemento la más reciente (el día anterior)\n",
    "    rss_df_sorted = rss_df.sort_values(\"published\", ascending = False)\n",
    "\n",
    "    #Obtengo el cierre anterior que es un archivo HTML\n",
    "    last_closed_link = rss_df_sorted[\"feedburner_origlink\"][0]\n",
    "\n",
    "    #Leo el archivo HTML del cierre del día anterior de la BMV\n",
    "    html_file = requests.get(last_closed_link).content\n",
    "\n",
    "    soup = BeautifulSoup(html_file)\n",
    "\n",
    "    return scrapping(soup)\n",
    "\n",
    "\n",
    "#######Funciones sobre el DataFrame######\n",
    "\n",
    "def drop_duplicates(df):\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "def drop_na_rows(df):\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def drop_na_columns(df):\n",
    "    null_cols = df.isnull().sum()\n",
    "    drop_cols = list(null_cols[null_cols > 10000].index)\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    return df \n",
    "\n",
    "def data_cleaning(df):\n",
    "    df = drop_duplicates(df)\n",
    "    df = drop_na_rows(df)\n",
    "    df = drop_na_columns(df)\n",
    "    return df\n",
    "    \n",
    "\n",
    "#####Cálculo de información importante\n",
    "def variacion_negativa(df):\n",
    "    df[\"Variación\"] = df[\"Variación\"].astype(float)\n",
    "    negativos = df[df[\"Variación\"] < 0]\n",
    "#     print(df.dtypes)\n",
    "    return negativos[\"Índice\", \"Último\", \"Hora\", \"Anterior\", \"Variación\", \"Variación Ptos.\", \"Máximo\", \"Hora\", \"Mínimo\", \"Hora\"]\n",
    "    \n",
    "    \n",
    "df = scrapping_RSS()\n",
    "df = data_cleaning(df)\n",
    "\n",
    "#Obtener los índices con variación negativa\n",
    "variacion_negativa(df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API CHALLENGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>neo_reference_id</th>\n",
       "      <th>is_potentially_hazardous_asteroid</th>\n",
       "      <th>absolute_magnitude_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(2019 KD3)</td>\n",
       "      <td>3842614</td>\n",
       "      <td>False</td>\n",
       "      <td>23.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2019 LT4)</td>\n",
       "      <td>3842864</td>\n",
       "      <td>False</td>\n",
       "      <td>24.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2019 NW5)</td>\n",
       "      <td>3843276</td>\n",
       "      <td>False</td>\n",
       "      <td>23.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(2019 JC47)</td>\n",
       "      <td>3842749</td>\n",
       "      <td>False</td>\n",
       "      <td>20.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(2019 NC)</td>\n",
       "      <td>3843081</td>\n",
       "      <td>False</td>\n",
       "      <td>24.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(2016 LM48)</td>\n",
       "      <td>3754252</td>\n",
       "      <td>False</td>\n",
       "      <td>20.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(2016 NJ33)</td>\n",
       "      <td>3755347</td>\n",
       "      <td>False</td>\n",
       "      <td>25.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(2017 FK3)</td>\n",
       "      <td>3771643</td>\n",
       "      <td>False</td>\n",
       "      <td>26.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>257744 (2000 AD205)</td>\n",
       "      <td>2257744</td>\n",
       "      <td>False</td>\n",
       "      <td>18.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>293054 (2006 WP127)</td>\n",
       "      <td>2293054</td>\n",
       "      <td>False</td>\n",
       "      <td>18.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2013 NT11)</td>\n",
       "      <td>3645001</td>\n",
       "      <td>False</td>\n",
       "      <td>19.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name neo_reference_id  is_potentially_hazardous_asteroid  \\\n",
       "0            (2019 KD3)          3842614                              False   \n",
       "1            (2019 LT4)          3842864                              False   \n",
       "2            (2019 NW5)          3843276                              False   \n",
       "3           (2019 JC47)          3842749                              False   \n",
       "4             (2019 NC)          3843081                              False   \n",
       "5           (2016 LM48)          3754252                              False   \n",
       "6           (2016 NJ33)          3755347                              False   \n",
       "7            (2017 FK3)          3771643                              False   \n",
       "8   257744 (2000 AD205)          2257744                              False   \n",
       "9   293054 (2006 WP127)          2293054                              False   \n",
       "10          (2013 NT11)          3645001                              False   \n",
       "\n",
       "    absolute_magnitude_h  \n",
       "0                 23.144  \n",
       "1                 24.184  \n",
       "2                 23.779  \n",
       "3                 20.501  \n",
       "4                 24.295  \n",
       "5                 20.500  \n",
       "6                 25.200  \n",
       "7                 26.200  \n",
       "8                 18.500  \n",
       "9                 18.300  \n",
       "10                19.600  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ovgTp7SJufoqcjr6g2205dt0KATD49AIMVY4ht5B\n",
    "# https://api.usa.gov/crime/fbi/sapi/\n",
    "# api = \"https://api.usa.gov/crime/fbi/sapi/api/data/arrest/national/offense/juvenile/2010/2019?api_key=ovgTp7SJufoqcjr6g2205dt0KATD49AIMVY4ht5B\"\n",
    "\n",
    "\n",
    "def get_response(start_date):\n",
    "    start_date_api = datetime.strptime(start_date, \"%Y-%m-%d\").date()\n",
    "    end_date = start_date_api + timedelta(days = 7)\n",
    "    url = f\"https://api.nasa.gov/neo/rest/v1/feed?start_date={start_date_api}&end_date={end_date}&api_key=T0tZNACEDXLIyexmdmTCSCrMemQ0u39v1syrwXzJ\"\n",
    "    response = requests.get(url)\n",
    "    asteroids_json = response.json()\n",
    "    asteroids_normalized = json_normalize(asteroids_json)\n",
    "    asteroids_df = pd.DataFrame(asteroids_normalized[f\"near_earth_objects.{start_date}\"][0])\n",
    "    asteroids_return_df = asteroids_df[[\"name\", \"neo_reference_id\", \"is_potentially_hazardous_asteroid\", \"absolute_magnitude_h\"]]\n",
    "    return asteroids_return_df\n",
    "\n",
    "   \n",
    "get_response(\"2019-07-12\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
